A Comprehensive Architectural and Methodological Guide for the CS6230 Viterbi Decoder ProjectSection 1: Architectural Blueprint for the Viterbi DecoderThis section establishes the foundational architectural strategy for the Viterbi Decoder project. It begins by deconstructing the Viterbi algorithm as specified, translating its mathematical principles into a high-level hardware paradigm. The analysis focuses on interpreting the project's unique constraints to derive a robust and compliant system architecture.1.1 The Viterbi Algorithm in the Logarithmic DomainThe Viterbi algorithm is a dynamic programming method for determining the most probable sequence of hidden states within a Hidden Markov Model (HMM) that could have produced a given sequence of observations.1 The project specification provides the core recursion formula that must be implemented 2:$$V_{t}(j) = \max_{1 \le i \le N} (V_{t-1}(i) + \log P(s_{j}|s_{i})) + \log P(o_{t}|s_{j})$$Here, $V_{t}(j)$ represents the maximum log-probability of any state sequence ending in state $j$ at time step $t$. A careful analysis of this formula is the most critical first step in defining the hardware architecture.The standard probabilistic form of the Viterbi algorithm involves multiplications: $V_t(j) = \max_{i} (V_{t-1}(i) \times P(s_j|s_i)) \times P(o_t|s_j)$.1 Performing multiplication with floating-point numbers in hardware is resource-intensive and complex. The project specification circumvents this by providing all transition probabilities ($A = \{a_{ij}\} = \{\log P(s_j|s_i)\}$) and emission probabilities ($B = \{b_j(o_t)\} = \{\log P(o_t|s_j)\}$) in their natural logarithmic form.2 This logarithmic transformation is a common technique in hardware and software implementations of probabilistic algorithms to enhance numerical stability and simplify computation. It leverages the mathematical property that the logarithm of a product is the sum of the logarithms: $\log(x \times y) = \log(x) + \log(y)$.Consequently, the core computational task of the Viterbi recursion is transformed from a series of multiplications into a series of additions. The max operation, which is fundamentally a comparison, remains unchanged. However, the project specification introduces a pivotal constraint: the direct use of the addition ('+') and multiplication ('*') operators for the floating-point data types is forbidden.2This set of requirements—log-domain probabilities simplifying multiplication to addition, coupled with a prohibition on the standard addition operator—deliberately shifts the central challenge of the project. The task is no longer primarily about implementing the high-level control flow of the Viterbi algorithm. Instead, it becomes a detailed, first-principles exercise in digital logic design: the creation of a custom IEEE 754 single-precision floating-point arithmetic logic unit (ALU) within the Bluespec SystemVerilog (BSV) framework. The Viterbi algorithm serves as the complex, real-world application that will drive and validate this custom ALU design. Therefore, the primary technical effort must be directed towards the meticulous, bit-level hardware design of a floating-point adder, as this will be the fundamental building block of the entire system.1.2 Decomposing the Algorithm into Hardware Kernels: BMU, ACSU, and SMUTo manage complexity and promote parallelism, the Viterbi decoder hardware is conventionally partitioned into three specialized, interacting units. This modular architecture is directly applicable to the log-domain HMM problem specified.4Branch Metric Unit (BMU): The BMU is responsible for calculating the "branch metric" for each possible state transition at a given time step. In the context of this project, for an observation $o_t$, the branch metric for a transition from a previous state $s_i$ to a current state $s_j$ is the sum of the log-transition and log-emission probabilities: $\log P(s_j|s_i) + \log P(o_t|s_j)$. The BMU will fetch these two logarithmic values from on-chip memories (pre-loaded from A.dat and B.dat) and perform the addition using the custom-designed floating-point adder. For a system with $N$ states, the BMU must compute up to $N \times N$ such branch metrics for each new observation.Add-Compare-Select Unit (ACSU): The ACSU is the recursive core of the Viterbi decoder and the primary performance bottleneck in high-speed designs.4 For each of the $N$ possible current states ($j=1...N$), the ACSU performs three sequential operations:Add: It takes the path metric of each possible predecessor state from the previous time step, $V_{t-1}(i)$, and adds the corresponding branch metric calculated by the BMU. This yields $N$ candidate path metrics for state $j$.Compare: It compares these $N$ candidate path metrics to find the one with the maximum value (since log-probabilities are used, a larger number is better).Select: It selects this maximum value as the new path metric for state $j$, $V_t(j)$, and outputs the index of the predecessor state $i$ that produced this maximum value.Survivor Memory Unit (SMU): The SMU is responsible for storing and reconstructing the most likely state sequence, known as the survivor path. At each time step $t$, for each state $j$, the SMU receives and stores the "winning" predecessor index from the corresponding ACSU. After the final observation is processed, the system identifies the state with the highest final path metric. The SMU then performs a "traceback" operation, starting from this final state and following the stored predecessor indices backward in time to reconstruct the complete Viterbi path.21.3 High-Level Data Flow and System TimingThe operation of the decoder can be visualized as a synchronous, pipelined data flow that processes one observation per computational epoch. An epoch may span one or more clock cycles depending on the degree of pipelining and parallelism. For a new observation $o_t$ arriving at the decoder:Cycle 1 (Fetch & BMU): The observation $o_t$ is used as an index to fetch the relevant emission probabilities, $\log P(o_t|s_j)$, from the B-matrix memory. Concurrently, transition probabilities, $\log P(s_j|s_i)$, are fetched from the A-matrix memory. The BMU computes the branch metrics.Cycle 2 (ACSU): The ACSUs receive the path metrics from the previous time step, $V_{t-1}$, which are stored in a register file or dual-port memory. They also receive the branch metrics from the BMU. The ACSUs perform the add-compare-select operation to compute the new path metrics, $V_t$, and the predecessor indices for the traceback.Cycle 3 (Write-back & SMU): The newly computed path metrics $V_t$ are written back into the path metric memory, overwriting the $V_{t-1}$ values in preparation for the next observation. Simultaneously, the predecessor indices generated by the ACSUs are written into the SMU.This process repeats for the entire length of the observation sequence. This inherently sequential, state-dependent computation lends itself well to a pipelined hardware implementation, which will be a key avenue for performance optimization.Table 1: Project Parameter and Constraint SummaryTo ensure compliance and guide the design process, all critical parameters and constraints from the project specification are consolidated below.2CategoryParameter / ConstraintSpecificationModel ParametersNumber of States ($N$)32-bit integer, read from N.dat.Number of Observations ($M$)32-bit integer, read from N.dat.Maximum Matrix Entries1024 entries for transition or emission probability matrices.Data TypesStates & Observations32-bit integers, 1-indexed.Probabilities (Transition/Emission)IEEE single-precision floating-point, stored as natural logarithms.File Formats (I/O)N.datContains $N$ and $M$.A.dat$(N+1) \times N$ transition log-probabilities.B.dat$N \times M$ emission log-probabilities.Input.datMultiple sequences of 32-bit integer observations.Output.datMost probable state sequence, log-probability score.Special MarkersEnd of Sequence32'hFFFFFFFF.End of File32'hFFFFFFFF followed by 32'h0.Core ConstraintsDesign LanguageBluespec SystemVerilog (BSV).Synthesis EnvironmentShakti Docker Image.Arithmetic ProhibitionNo direct use of '+' or '*' operators for arithmetic operations.VerificationMemory LoadingUse mkRegFileLoad in the testbench.Output GenerationUse $fwrite in the testbench.Reference ModelRequired, in any language, with matching output format for comparison.Section 2: Mastering the Bluespec Design ParadigmA successful implementation requires a firm grasp of the Bluespec SystemVerilog (BSV) design philosophy. This section provides a focused overview of the BSV concepts most relevant to this project, moving from the language's core principles to a recommended structure for organizing the source code.2.1 A Primer on Guarded Atomic Actions and Interface-Driven DesignBSV departs from traditional Hardware Description Languages (HDLs) like Verilog and VHDL by abstracting hardware behavior into a system of Guarded Atomic Actions, commonly known as "rules".8 This paradigm offers a more robust way to manage the complexity of concurrent systems.Core Philosophy: A BSV design is composed of state elements (e.g., registers, FIFOs, memories) and a collection of rules that operate on this state. The execution model is simple yet powerful: in any given clock cycle, the compiler generates hardware that will:Evaluate the "guard" (a boolean condition) of every rule in the design.Select one or more non-conflicting rules whose guards are true.Execute the "action" part of these selected rules, updating the state.This execution is atomic, meaning the state change appears to happen instantaneously and indivisibly from the perspective of all other rules. This atomicity eliminates entire classes of concurrency bugs, such as race conditions, that are common in traditional HDL design.9 The parallel ACSU computations in the Viterbi decoder are a prime example where this model simplifies design reasoning.Modules and Interfaces: BSV promotes a highly modular, hierarchical design style through its strong separation of interfaces from implementations, analogous to object-oriented programming.10An interface defines a set of methods that a module exposes to the outside world. Methods can be Action methods (which modify state), Value methods (which read state and return a value), or ActionValue methods (which do both).A module is a unit of hardware that implements one or more interfaces.This approach, demonstrated effectively in introductory tutorials like "Designing a Counter" 12, allows for the independent development and testing of each component (BMU, ACSU, SMU) before they are integrated into the final system.2.2 Structuring Your Project: A Professional Directory LayoutA well-organized project structure is essential for managing complexity, separating concerns, and streamlining the build and verification process. Based on best practices observed in mature open-source BSV projects, the following directory layout is recommended 13:viterbi_project/
├── src/                  # All.bsv source files
│   ├── lib/              # Reusable components (e.g., FPAdder.bsv)
│   ├── ViterbiTypes.bsv  # Global type definitions (e.g., StateIndex, LogProb)
│   ├── ViterbiDecoder.bsv# Top-level decoder module and its sub-modules
│   └── Tb.bsv            # Top-level testbench module
├── build/                # Output directory for compiler artifacts (Verilog,.o,.so)
├── verification/
│   ├── reference_model/  # Python-based golden reference model
│   │   └── viterbi_ref.py
│   └── test_cases/       # Input data files (small, huge, custom-generated)
│       ├── small/
│       └── huge/
├── reports/              # Synthesis reports (PPA, timing, etc.)
├── Makefile              # Top-level makefile for automating the entire flow
└── README.md             # Project documentation and instructions
This structure clearly separates the hardware source code (src), verification assets (verification), build products (build), and final analysis (reports). The top-level Makefile will serve as the central point of control for compiling, simulating, verifying, and synthesizing the design.2.3 Defining Module Interfaces for a Hierarchical DesignFollowing the interface-driven design principle, one should first define the BSV interface for each major hardware block. This acts as a contract between the different parts of the system, allowing for concurrent development and modular testing.Example: ACSU InterfaceAn interface for a single ACSU processing element (calculating the path metric for one state j) might be defined as follows. This element needs to be fed the previous path metrics and branch metrics one by one, and then it will provide the final result.Code snippet// In ViterbiTypes.bsv
typedef Bit#(32) LogProb;
typedef Bit#(5)  StateIndex; // Assuming N <= 32

// In ViterbiDecoder.bsv
interface AcsuIfc;
    // Method to feed one of the N inputs (prev path metric + branch metric)
    method Action putCandidate(LogProb candidateMetric, StateIndex predIndex);

    // Method to signal that all N candidates have been provided
    method Action endOfCandidates();

    // Method to retrieve the final result (max probability and its predecessor)
    method ActionValue#(Tuple2#(LogProb, StateIndex)) getResult();
endinterface
This interface defines a clear protocol: the testbench or top-level module will call putCandidate $N$ times, then call endOfCandidates, and finally call getResult to read the output. This modular approach is a cornerstone of robust hardware design and is strongly supported by the BSV language and its associated tools.9Section 3: Core Microarchitecture and Implementation in BSVThis section provides a detailed, step-by-step guide to implementing the core hardware modules in BSV, with a primary focus on overcoming the project's central arithmetic constraint.3.1 Input Data Ingestion and Output Formatting ModulesThe project specification dictates that the testbench is responsible for loading the probability matrices into the hardware module using the mkRegFileLoad utility.2 This implies that the Viterbi Decoder module itself will contain memory structures to store the A and B matrices. RegFile, a library component in BSV, is suitable for this purpose, as it provides a simple read/write interface.Memory Subsystem: The decoder module will instantiate two register files: a_matrix and b_matrix. The interface to the decoder will not involve passing the entire matrices but rather providing indices. For example, a method getTransitionProb(StateIndex from, StateIndex to) would read from a_matrix.Observation Stream Handling: The sequence of observations from Input.dat should be streamed into the decoder. A FIFO (First-In, First-Out) buffer is the ideal BSV construct for this. The testbench will enqueue observations into the FIFO, and the decoder's main control logic will dequeue one observation at the beginning of each processing epoch.Output Generation: The final computed state sequence and log-probability will be exposed through methods on the decoder's top-level interface. The testbench will call these methods and use the $fwrite system task to write the results to output.dat, ensuring strict adherence to the specified format, including the 32'hFFFFFFFF markers.23.2 The Central Challenge: Implementing an IEEE 754 Floating-Point AdderThis sub-section provides a microarchitectural blueprint for a single-precision floating-point adder that complies with the "no '+'" constraint. The design will be built from first principles, following the standard hardware algorithm for floating-point addition.163.2.1 Deconstructing Operands and Handling Special ValuesThe first stage of the adder pipeline must parse the two 32-bit input vectors (opA and opB) into their constituent fields: sign ($S_A, S_B$), exponent ($E_A, E_B$), and mantissa ($M_A, M_B$).Code snippet// In lib/FPAdder.bsv
let signA = opA;
let expA  = opA[30:23];
let manA  = opA[22:0];
// Similarly for opB
This stage must also include logic to detect and handle special IEEE 754 values.18Zero: If exp and man are all zeros.Infinity: If exp is all ones and man is all zeros.NaN (Not a Number): If exp is all ones and man is non-zero.Logic must correctly implement operations like Inf + x = Inf, NaN + x = NaN, etc. For normalized numbers (where $0 < E < 255$), the implicit leading '1' must be prepended to the mantissa to form a 24-bit significand.3.2.2 Mantissa Alignment via Barrel ShiftersFloating-point addition can only be performed on numbers with the same exponent. Therefore, the significand of the number with the smaller exponent must be arithmetically right-shifted to align the binary points.16Exponent Comparison: The exponents $E_A$ and $E_B$ are subtracted to find the shift amount, shift_val = |E_A - E_B|. The larger exponent becomes the preliminary exponent of the result.Operand Swapping: The operands are swapped if necessary so that the operand with the smaller exponent is always the one being shifted.Shifting: A barrel shifter is required to perform a variable right-shift on the smaller significand by shift_val bits. A barrel shifter can be implemented in BSV as a series of multiplexers, allowing for a shift by any amount in a single clock cycle. The bits shifted out are not discarded; they are used to compute the "guard," "round," and "sticky" bits required for accurate rounding later. The sticky bit is the logical OR of all bits shifted out beyond the guard and round bits.3.2.3 Building the Mantissa Adder from Bitwise LogicThis is the implementation that directly satisfies the project's core constraint. A 24-bit adder for the aligned significands will be constructed without using the + operator. This is achieved by building a ripple-carry adder from 24 instances of a full-adder module.20A full-adder is a combinational circuit that adds three single bits ($A$, $B$, $C_{in}$) and produces a sum ($S$) and a carry-out ($C_{out}$). Its logic can be expressed purely with bitwise operators:$S = A \oplus B \oplus C_{in}$ (where $\oplus$ is XOR)$C_{out} = (A \wedge B) \vee (B \wedge C_{in}) \vee (A \wedge C_{in})$ (where $\wedge$ is AND, $\vee$ is OR)This can be implemented as a BSV function:Code snippet// In lib/FPAdder.bsv
function Tuple2#(Bit#(1), Bit#(1)) full_adder(Bit#(1) a, Bit#(1) b, Bit#(1) cin);
    Bit#(1) sum = a ^ b ^ cin;
    Bit#(1) cout = (a & b) | (b & cin) | (a & cin);
    return tuple2(cout, sum);
endfunction
A 24-bit ripple-carry adder is then constructed by chaining 24 of these full_adder functions, where the cout from one stage becomes the cin for the next. While slow due to the long carry-propagation chain, this approach is functionally correct and strictly adheres to the constraint.3.2.4 Normalization and Rounding LogicThe result from the mantissa adder may not be in normalized form. The final stage of the FP adder must correct this.Normalization: The resulting 24-bit sum may have overflowed (requiring a 1-bit right shift and exponent increment) or may have leading zeros (in the case of effective subtraction), requiring a multi-bit left shift and exponent decrement. A leading-zero counter is used to determine the required left shift amount, which is then performed by another barrel shifter.17Rounding: The final normalized mantissa must be rounded to 23 bits. The decision to round up is based on the guard, round, and sticky bits computed during the alignment phase. The default "round to nearest, ties to even" mode is typically implemented. Rounding can potentially cause the mantissa to overflow, which requires another normalization step.Reassembly: Finally, the new sign, adjusted exponent, and rounded mantissa are reassembled into a 32-bit floating-point number.3.3 Designing the Parallel Add-Compare-Select Unit (ACSU)A high-performance Viterbi decoder will employ a state-parallel architecture, with one ACSU dedicated to each of the $N$ states.4ACSU Microarchitecture: For each state $j$, ACSU$j$ receives the $N$ path metrics from the previous step, $V{t-1}(i)$, and the $N$ corresponding branch metrics. It will contain $N$ instances of the custom floating-point adder to compute all $N$ candidate path metrics in parallel: $V_{t-1}(i) + \text{BranchMetric}(i, j)$ for $i=1...N$.Comparator Tree: The outputs of these $N$ adders feed into a comparator tree. This is a network of 2-input comparators arranged in a tree structure to efficiently find the maximum value among the $N$ candidates in $\log_2(N)$ stages.Output: The final output of ACSU$_j$ is a tuple containing the maximum path metric found (which becomes $V_t(j)$) and the index of the predecessor state $i$ that generated it.3.4 Survivor Path Memory and Traceback Logic ImplementationThe SMU stores the decisions made by the ACSUs and reconstructs the final path. While a simple approach is to store all predecessor indices in a large memory and perform a sequential traceback at the end, a more hardware-efficient method is the Register Exchange technique.7Register Exchange Method: In this architecture, there are $N$ registers, one for each state. Each register is wide enough to store the entire decoded path up to the current time step. At time $t$, when ACSU$_j$ determines that state $i$ is the optimal predecessor, the contents of the path register for state $i$ are copied, the new state $j$ is appended, and this new, longer path is written into the path register for state $j$. This happens in parallel for all $N$ states. After the final observation, the path in the register corresponding to the final winning state is the complete Viterbi path. This avoids the need for a separate, time-consuming traceback FSM.Final Path Selection: After processing the last observation, a final comparison of all $N$ path metrics identifies the state with the overall highest probability. The contents of the corresponding path register in the SMU are then read out as the final result.Section 4: A Rigorous Verification FrameworkThe project specification places a strong emphasis on verification, requiring a software reference model, a comprehensive BSV testbench, and automation of the comparison process.2 This section outlines a professional-grade verification strategy to ensure correctness.4.1 Developing the Python-Based Golden Reference ModelA "golden" reference model is an executable specification that provides the correct output for any given input. Python is an ideal choice for this task due to its simplicity and powerful libraries.The starting point can be a well-established open-source Viterbi implementation in Python.25 However, this base implementation must be significantly adapted to serve as a true golden model for this specific project.File I/O: The Python script must be modified to parse the exact input file formats (N.dat, A.dat, B.dat, Input.dat) and generate an output file (golden_output.dat) that is bit-for-bit identical in format to the hardware's expected output.Precision and Rounding Awareness: This is a subtle but critical aspect of verification. Standard Python floats are 64-bit double-precision, whereas the hardware design uses 32-bit single-precision. This discrepancy can lead to small rounding differences that cause verification failures, even if the hardware logic is correct. To create a reliable, bit-exact reference, the Python model must be constrained to operate with the same numerical precision as the hardware. This can be achieved by using the numpy.float32 data type for all probability calculations. Furthermore, the rounding behavior of the custom hardware adder (e.g., round-to-nearest-even) should be explicitly modeled in the Python code to ensure that the software and hardware produce identical results under all conditions. A naive model using default float types is insufficient and will likely lead to frustrating debugging sessions.4.2 Constructing the BSV Testbench: File I/O and DUT InstantiationThe BSV testbench (mkTb) is a non-synthesizable module that orchestrates the simulation. Its primary responsibilities are to mimic the external world for the Device Under Test (DUT), the ViterbiDecoder module.Instantiation: The testbench begins by instantiating the ViterbiDecoder.12Code snippet// In src/Tb.bsv
ViterbiDecoder dut <- mkViterbiDecoder();
File Loading: It will use BSV's file handling capabilities to read the data from the .dat files. The probability matrices will be loaded into RegFile structures using the specified mkRegFileLoad utility.Driving the DUT: The testbench will contain a finite-state machine (FSM) that reads one observation sequence at a time from the loaded input data. It will feed the observations to the DUT, likely via a FIFO interface, and wait for the DUT to signal completion.Capturing Output: Upon completion, the testbench will call the DUT's output methods to retrieve the decoded state sequence and final log-probability. It will then use the $fwrite system task to write these values to design_output.dat, carefully formatting the output to match the specification, including the hexadecimal markers.24.3 Automating the Simulation-to-Reference Comparison FlowTo satisfy the requirement for an automated setup, a master Makefile or a shell script should be created to manage the entire verification flow. This script will provide a single command to run a complete test.A target in the Makefile could look like this:Makefile.PHONY: test
test:
    @echo "Running test case: $(TEST_CASE)"
    # Step 1: Run the golden reference model
    python3 verification/reference_model/viterbi_ref.py \
        --test_dir verification/test_cases/$(TEST_CASE) \
        --output verification/golden_output.dat

    # Step 2: Compile and run the BSV simulation
    make -C build run_sim TEST_CASE=$(TEST_CASE)

    # Step 3: Compare the results
    @echo "Comparing design output with golden reference..."
    @diff --brief build/output.dat verification/golden_output.dat > /dev/null; \
    if [ $$? -eq 0 ]; then \
        echo " for $(TEST_CASE)"; \
    else \
        echo " for $(TEST_CASE)"; \
        diff build/output.dat verification/golden_output.dat; \
        exit 1; \
    fi
This automated flow, which can be invoked with a simple make test TEST_CASE=small, dramatically improves productivity and reduces the chance of manual error.4.4 A Strategy for Comprehensive Test Case GenerationThe project requires the development of custom test cases beyond the two provided.2 A robust verification plan must cover a wide range of scenarios to uncover potential bugs.Corner Cases:Minimal Model: Test with $N=1, M=1$.Sequence Length: Test with very short (1 observation) and very long sequences.Special Inputs: Test sequences that contain only one unique observation.Probability-Driven Tests:Extreme Values: Use log-probabilities that are very large negative numbers (close to zero probability) or close to zero (high probability).Path Ambiguity: Manually craft transition and emission matrices where multiple paths have identical or nearly identical probabilities. This will stress the max selection logic in the ACSU and the rounding precision of the custom FP adder.Randomized Generation: A Python script should be developed to generate large, valid, and randomized test cases. This script would generate random N and M values (within the project limits), create valid probability matrices (ensuring probabilities sum to 1 before converting to log), and generate long random observation sequences. Running hundreds of such tests provides strong statistical confidence in the design's robustness.Section 5: Synthesis and Performance Optimization within the Shakti EcosystemThis section addresses the final stage of the project: synthesizing the BSV design into a hardware netlist using the provided Shakti tools and then optimizing the design to demonstrate a measurable improvement in power, performance, or area (PPA).5.1 Navigating the Shakti Docker Environment and Synthesis FlowThe project must be compiled and synthesized using the provided Shakti Docker Image.2 The setup process generally involves the following steps, which should be followed based on the official Shakti documentation 33:Docker Setup: Install Docker on the host machine (Linux or Windows with WSL).Image Build: Clone the necessary Shakti repositories and use the provided docker-compose files to build the Shakti development environment image. This image will contain the BSV compiler (bsc), a Verilog simulator (like Verilator), and likely an FPGA synthesis toolchain (like Xilinx Vivado).Container Execution: Start a container from the built image. This provides an isolated shell environment with all the necessary tools pre-installed and configured.The synthesis flow within this environment is typically a two-step process automated by a Makefile 35:BSV to Verilog Compilation: The BSV source code is first compiled into synthesizable Verilog RTL using the bsc compiler (e.g., bsc -verilog -g mkViterbiDecoder ViterbiDecoder.bsv).RTL Synthesis: The generated Verilog code is then passed as input to an FPGA synthesis tool (e.g., Vivado). The synthesis tool, guided by constraint files (specifying the target clock frequency), converts the RTL into a gate-level netlist and generates reports on resource utilization and timing.5.2 Analyzing the Baseline Design: Interpreting Synthesis Reports for PPAThe first step after achieving functional correctness is to synthesize the initial, unoptimized "baseline" design. The synthesis tool will produce detailed reports that must be analyzed to establish a baseline for PPA metrics.39 The key figures to extract are:Performance (P): The maximum clock frequency (Fmax) is the most important performance metric. It is determined by the "critical path," the longest combinational logic delay between any two sequential elements in the design. This will be reported as "Worst Negative Slack" (WNS) or a similar timing summary.Area (A): This is reported as resource utilization. For an FPGA target, this includes the number of Look-Up Tables (LUTs), Flip-Flops (FFs), Digital Signal Processors (DSPs), and Block RAMs (BRAMs) consumed by the design.Power (P): The synthesis tool provides an estimate of the total power consumption, typically broken down into static power (leakage) and dynamic power (switching activity).5.3 Advanced Optimization Techniques: Pipelining, Resource Sharing, and Architectural Trade-offsThe project requires demonstrating a "measurable improvement" in PPA from the baseline to the final design.2 This requires implementing one or more optimization strategies.Pipelining for Performance: The critical path in the baseline design will almost certainly be within the complex, multi-stage logic of the custom floating-point adder or the subsequent comparator tree in the ACSU. Pipelining is the most effective technique to improve Fmax. This involves inserting registers at strategic points within a long combinational path, breaking it into shorter stages.FP Adder Pipelining: The custom FP adder can be broken into at least three pipeline stages: (1) Unpack & Align, (2) Mantissa Add, (3) Normalize & Round. Placing registers between these stages will dramatically shorten the critical path and increase the achievable clock frequency.ACSU Loop Pipelining: The entire ACSU operation (Add -> Compare -> Select) can also be pipelined. This increases the latency (number of cycles to process one observation) but allows the clock to run much faster, potentially increasing overall throughput (observations processed per second).Resource Sharing for Area: The fully parallel architecture with $N$ ACSUs and $N^2$ FP adders may consume a large amount of area. If area reduction is the optimization goal, resource sharing is a viable strategy. Instead of $N$ parallel ACSUs, the design could use a single, deeply pipelined ACSU. The computation for the $N$ states would then be serialized, taking $N$ clock cycles to process one observation. This represents a classic area-performance trade-off: logic area is significantly reduced at the cost of lower throughput.Table 2: PPA Optimization Strategies and Expected OutcomesThe choice of optimization strategy should be a deliberate one, based on a clear goal. The following table summarizes the trade-offs.Optimization StrategyPerformance (Fmax)Area (LUTs/FFs)Throughput (Obs/sec)Design ComplexityBest For...Deep Pipelining of FP AdderHigh IncreaseModerate Increase (due to added pipeline registers)HighMediumAchieving the highest clock frequency.Full ACSU Loop PipeliningVery High IncreaseHigh Increase (many pipeline registers)Very HighHighMaximizing overall throughput.ACSU Serialization/Resource SharingDecreaseHigh Decrease (fewer functional units)LowMediumMinimizing logic area and power consumption.Section 6: Strategic Use of External Repositories and DocumentationThe project specification has a strict policy on academic integrity.2 This section provides clear guidelines on how to leverage public resources ethically and effectively to enhance learning without committing plagiarism.6.1 A Note on Academic Integrity and Project PoliciesThe project ground rules explicitly state: "Sharing of code between student groups and/or copying from public git repositories will be considered cheating".2 The tools available to the teaching staff for code similarity detection are sophisticated. Any attempt to submit code that is not one's own work will be flagged, leading to severe academic penalties. The objective of this project is to engage in the process of design, implementation, and verification. The following guidelines are intended to facilitate learning while respecting this core principle.6.2 Recommended Resources for Learning BSV ConceptsThe use of external resources to learn the BSV language itself is not only permitted but essential. The primary sources should be the official documentation and tutorials provided by Bluespec and academic institutions.Official Documentation: The BSV Reference Guide, User Guide, and Style Guide are invaluable resources for syntax and library usage.15Tutorials and Labs: Hands-on tutorials, such as those for designing a counter or a simple pipeline, are excellent for understanding the BSV design flow and core concepts.12Example Repositories: Repositories like govardhnn/Bluespexamples 14 should be studied to understand common coding patterns, project structure, and BSV syntax in practice. The code within these repositories should be treated as reference material, not as a source for copy-pasting.6.3 Architectural Patterns from Viterbi Decoder LiteratureIt is a standard engineering practice to study existing solutions to understand common architectural patterns. Reviewing academic papers and public Verilog implementations of Viterbi decoders can provide valuable high-level insights.4 The purpose of this review is to understand:The standard decomposition into BMU, ACSU, and SMU blocks.The trade-offs between different SMU implementations (e.g., register exchange vs. traceback).Techniques for parallelization and pipelining specific to the Viterbi algorithm.After studying these concepts, the actual implementation in BSV must be done from scratch. The intellectual work lies in translating these high-level architectural ideas into a new, functional BSV design.6.4 Leveraging Python Repositories for the Reference ModelThe development of the software reference model is a verification task, not a hardware design task. In this context, leveraging existing code is an accepted and efficient practice. Public Python repositories implementing the Viterbi algorithm are excellent starting points for the golden model.25 The required original work in this part of the project involves:Adapting the code to read and write the specific file formats required by the project.Modifying the data types (e.g., to numpy.float32) and arithmetic to ensure it is a bit-exact model of the hardware's behavior.Integrating the script into the automated verification Makefile.Section 7: Finalizing the Project and Submission ReportThe final phase of the project involves documenting the work and preparing the submission package according to the specified requirements.7.1 A Summary of the Design and Optimization JourneyThe final report is a critical component of the submission and must be detailed and professional.2 It should narrate the entire project lifecycle. A recommended structure is:Introduction: Briefly describe the Viterbi algorithm and the project objectives.Baseline Microarchitecture: Detail the initial, functionally correct design. Explain the decomposition into BMU, ACSU, and SMU. Provide block diagrams. Crucially, provide a detailed description of the custom floating-point adder implementation.Verification Methodology: Describe the Python reference model (including the precision-aware modifications), the BSV testbench structure, and the automated verification flow. Justify the choice and scope of the custom-generated test cases.Synthesis Results and Analysis of Baseline Design: Present the PPA results (Fmax, Area, Power) for the baseline design. Identify the critical path and other performance bottlenecks based on the synthesis reports.Optimization Strategy and Implementation: State the chosen optimization goal (e.g., "maximize clock frequency"). Describe the technique used (e.g., "pipelining the FP adder") and explain the changes made to the baseline microarchitecture to implement it.Final Results and Comparison: Present the PPA results for the final, optimized design. Create a table comparing the baseline and final designs, clearly showing the "measurable improvement" achieved.Conclusion: Summarize the project, the design challenges, and the final results.7.2 Checklist for the Final Submission PackageBefore submitting, ensure the final ZIP file contains all required components as per Section 6 of the project specification.2[ ] Single ZIP File: The entire submission is contained within one .zip archive.[ ] Complete Source Code:All .bsv source files for the design and testbench.The Python reference model.The automated Makefile and any associated scripts.All test cases used for verification.[ ] Detailed Report: A comprehensive PDF report covering the microarchitecture, verification, and optimization as described above.[ ] Synthesis Reports: The relevant synthesis and timing reports from the toolchain are included, either in the appendix of the report or as separate files.[ ] README File:A high-level overview of the design.A clear summary of individual contributions for each team member.Step-by-step instructions for compiling and executing the simulation and verification flow.A clear statement of the maximum clock frequency achieved by the final design.